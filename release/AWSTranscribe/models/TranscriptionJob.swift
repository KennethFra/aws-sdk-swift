// Code generated by smithy-swift-codegen. DO NOT EDIT!

import ClientRuntime

extension TranscribeClientTypes {
    /// Describes an asynchronous transcription job that was created with the StartTranscriptionJob operation.
    public struct TranscriptionJob: Swift.Equatable {
        /// A timestamp that shows when the job completed.
        public var completionTime: ClientRuntime.Date?
        /// An object that describes content redaction settings for the transcription job.
        public var contentRedaction: TranscribeClientTypes.ContentRedaction?
        /// A timestamp that shows when the job was created.
        public var creationTime: ClientRuntime.Date?
        /// If the TranscriptionJobStatus field is FAILED, this field contains information about why the job failed. The FailureReason field can contain one of the following values:
        ///
        /// * Unsupported media format - The media format specified in the MediaFormat field of the request isn't valid. See the description of the MediaFormat field for a list of valid values.
        ///
        /// * The media format provided does not match the detected media format - The media format of the audio file doesn't match the format specified in the MediaFormat field in the request. Check the media format of your media file and make sure that the two values match.
        ///
        /// * Invalid sample rate for audio file - The sample rate specified in the MediaSampleRateHertz of the request isn't valid. The sample rate must be between 8,000 and 48,000 Hertz.
        ///
        /// * The sample rate provided does not match the detected sample rate - The sample rate in the audio file doesn't match the sample rate specified in the MediaSampleRateHertz field in the request. Check the sample rate of your media file and make sure that the two values match.
        ///
        /// * Invalid file size: file size too large - The size of your audio file is larger than Amazon Transcribe can process. For more information, see [Limits](https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits) in the Amazon Transcribe Developer Guide.
        ///
        /// * Invalid number of channels: number of channels too large - Your audio contains more channels than Amazon Transcribe is configured to process. To request additional channels, see [Amazon Transcribe Limits](https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits-amazon-transcribe) in the Amazon Web Services General Reference.
        public var failureReason: Swift.String?
        /// A value between zero and one that Amazon Transcribe assigned to the language that it identified in the source audio. Larger values indicate that Amazon Transcribe has higher confidence in the language it identified.
        public var identifiedLanguageScore: Swift.Float?
        /// A value that shows if automatic language identification was enabled for a transcription job.
        public var identifyLanguage: Swift.Bool?
        /// Provides information about how a transcription job is executed.
        public var jobExecutionSettings: TranscribeClientTypes.JobExecutionSettings?
        /// The language code for the input speech.
        public var languageCode: TranscribeClientTypes.LanguageCode?
        /// Language-specific settings that can be specified when language identification is enabled for your transcription job. These settings include VocabularyName, VocabularyFilterName, and LanguageModelNameLanguageModelName.
        public var languageIdSettings: [Swift.String:TranscribeClientTypes.LanguageIdSettings]?
        /// An object that shows the optional array of languages inputted for transcription jobs with automatic language identification enabled.
        public var languageOptions: [TranscribeClientTypes.LanguageCode]?
        /// An object that describes the input media for the transcription job.
        public var media: TranscribeClientTypes.Media?
        /// The format of the input media file.
        public var mediaFormat: TranscribeClientTypes.MediaFormat?
        /// The sample rate, in Hertz, of the audio track in the input media file.
        public var mediaSampleRateHertz: Swift.Int?
        /// An object containing the details of your custom language model.
        public var modelSettings: TranscribeClientTypes.ModelSettings?
        /// Optional settings for the transcription job. Use these settings to turn on speaker recognition, to set the maximum number of speakers that should be identified and to specify a custom vocabulary to use when processing the transcription job.
        public var settings: TranscribeClientTypes.Settings?
        /// A timestamp that shows when the job started processing.
        public var startTime: ClientRuntime.Date?
        /// Generate subtitles for your batch transcription job.
        public var subtitles: TranscribeClientTypes.SubtitlesOutput?
        /// A key:value pair assigned to a given transcription job.
        public var tags: [TranscribeClientTypes.Tag]?
        /// An object that describes the output of the transcription job.
        public var transcript: TranscribeClientTypes.Transcript?
        /// The name of the transcription job.
        public var transcriptionJobName: Swift.String?
        /// The status of the transcription job.
        public var transcriptionJobStatus: TranscribeClientTypes.TranscriptionJobStatus?

        public init (
            completionTime: ClientRuntime.Date? = nil,
            contentRedaction: TranscribeClientTypes.ContentRedaction? = nil,
            creationTime: ClientRuntime.Date? = nil,
            failureReason: Swift.String? = nil,
            identifiedLanguageScore: Swift.Float? = nil,
            identifyLanguage: Swift.Bool? = nil,
            jobExecutionSettings: TranscribeClientTypes.JobExecutionSettings? = nil,
            languageCode: TranscribeClientTypes.LanguageCode? = nil,
            languageIdSettings: [Swift.String:TranscribeClientTypes.LanguageIdSettings]? = nil,
            languageOptions: [TranscribeClientTypes.LanguageCode]? = nil,
            media: TranscribeClientTypes.Media? = nil,
            mediaFormat: TranscribeClientTypes.MediaFormat? = nil,
            mediaSampleRateHertz: Swift.Int? = nil,
            modelSettings: TranscribeClientTypes.ModelSettings? = nil,
            settings: TranscribeClientTypes.Settings? = nil,
            startTime: ClientRuntime.Date? = nil,
            subtitles: TranscribeClientTypes.SubtitlesOutput? = nil,
            tags: [TranscribeClientTypes.Tag]? = nil,
            transcript: TranscribeClientTypes.Transcript? = nil,
            transcriptionJobName: Swift.String? = nil,
            transcriptionJobStatus: TranscribeClientTypes.TranscriptionJobStatus? = nil
        )
        {
            self.completionTime = completionTime
            self.contentRedaction = contentRedaction
            self.creationTime = creationTime
            self.failureReason = failureReason
            self.identifiedLanguageScore = identifiedLanguageScore
            self.identifyLanguage = identifyLanguage
            self.jobExecutionSettings = jobExecutionSettings
            self.languageCode = languageCode
            self.languageIdSettings = languageIdSettings
            self.languageOptions = languageOptions
            self.media = media
            self.mediaFormat = mediaFormat
            self.mediaSampleRateHertz = mediaSampleRateHertz
            self.modelSettings = modelSettings
            self.settings = settings
            self.startTime = startTime
            self.subtitles = subtitles
            self.tags = tags
            self.transcript = transcript
            self.transcriptionJobName = transcriptionJobName
            self.transcriptionJobStatus = transcriptionJobStatus
        }
    }

}
